# -*- coding: utf-8 -*-
"""Course work.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mmgyMW1iP8bVwNbsjm8dFIdaSL1bNziE

# Необходимые импорты и загрузка данных
"""

pip install catboost

pip install shap

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.cross_decomposition import PLSRegression as PLS
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.impute import KNNImputer
import scipy.stats as sps
from sklearn.metrics import roc_auc_score, roc_curve
from tqdm import tqdm
import math
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import LeaveOneOut
from sklearn.ensemble import GradientBoostingClassifier as GBC
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from sklearn.svm import SVC
from sklearn.utils import resample
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.svm import SVC
from catboost import CatBoostClassifier, Pool
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.inspection import permutation_importance
import shap
from tqdm import tqdm

X = pd.read_excel('Data.xlsx')
y = X.group

def log_transform(df, columns, shift=1):
    """
    Функция логарифмирования данных
    """
    df_copy = df.copy()
    for col in columns:
        if col in df_copy.columns:
            # Добавляем shift, чтобы избежать log(0) или отрицательных значений
            df_copy[col] = np.log(df_copy[col] + 1)
        else:
            print(f"Внимание: столбец '{col}' не найден в DataFrame")
    return df_copy


features = ['p-HPhLA', 'p-HBA', 'p-HPhAA', 'PhLA', '5HIAA','3ILA', '3IPA', '3ICA', '3IAA', 'IL_6', 'NSE', 'S100']
x_data = X.loc[:,features]
y_data = X.group

amm_rus = ['п-ГФМК', 'п-ГБК', 'п-ГФУК',  'ФМК', '5ГИУК', '3ИМК', '3ИКК', '3ИУК',  '3ИПК', 'ИЛ-6','НСЕ', 'S100']
array = pd.concat([pd.DataFrame(StandardScaler().fit_transform(x_data), columns = amm_rus), pd.DataFrame(y_data)], axis = 1)
print(array.columns)
n_features = 12

# Определяем количество строк и столбцов для подграфиков (например, 3 в ряд)
n_cols = 7
n_rows = 3
a = 24
b = 18
plt.figure(figsize=(5 * n_cols, 4 * n_rows))

#Выводим распределения признаков
for i, col in enumerate(array.columns[:-1], 1):
    plt.subplot(n_rows, n_cols, i)
    sns.histplot(array[col], kde=False, bins=30)
    plt.title(f'Распределение {col}', fontsize = a)
    plt.xlabel(col, fontsize = b)
    plt.ylabel('Частота', fontsize = b)

plt.tight_layout()
plt.show()

"""# Статистика"""

def highlight_max(s, props=''):
    return np.where(s <=0.05, props, '')
def smash(x):
  return f"{x:.2f}".replace('.', ',')
def bci(data):
  lb = np.percentile(data, 25)
  med = np.percentile(data, 50)
  ub = np.percentile(data, 75)
  return smash(lb), smash(ub) ,smash(med)
def shap(p, q):
  return sps.shapiro(p).pvalue<0.05 and sps.shapiro(q).pvalue<0.05


a = x_data.loc[y_data==0]
b = x_data.loc[y_data==1]
c = pd.concat([a,b], axis=0)
feat = a.columns
print(feat)
#mannwhitneyu
test2 = sps.mannwhitneyu
test1 = sps.ttest_ind
norm_res =               pd.DataFrame(['ttest' if shap(a[i], b[i]) else 'mwu' for i in feat], index = feat) # проверка на нормальность - 0-ttest, 1-mannwhitneyu
ans_ts = pd.DataFrame((test1(a[i], b[i]) if shap(a[i], b[i]) else test2(a[i],b[i]) for i in feat))
mean_0 = pd.DataFrame([[f"{bci(a[i])[2]} ({bci(a[i])[0]}; {bci(a[i])[1]})" for i in feat]], columns = feat, index = ['median_0'])
mean_1 = pd.DataFrame([[f"{bci(b[i])[2]} ({bci(b[i])[0]}; {bci(b[i])[1]})" for i in feat]], columns = feat, index = ['median_1'])
mean_all = pd.DataFrame([[f"{bci(c[i])[2]} ({bci(c[i])[0]}; {bci(c[i])[1]})" for i in feat]], columns = feat, index = ['median_all'])
ans = pd.concat([
                pd.DataFrame([str(f"{i:.2f}").replace('.', ',') for i in ans_ts.iloc[:,1]])
                 ],
                 axis =1)
ans = pd.DataFrame(np.array(ans.T), columns = feat, index = ['two-sided'])
ans = pd.concat([ mean_all, mean_0, mean_1, ans
                 , norm_res.T
                  ], axis = 0)
rows = ['two-sided']
ans = ans.T
f = ans.style #.apply(highlight_max, props='color:white;background-color:darkblue',subset=pd.IndexSlice[:,rows])
f
#f.to_excel('database1 vs database2.xlsx', engine='openpyxl')

"""# ROC-анализ"""

# @title
def CI(data):
    median = np.percentile(data, 50)
    lower = np.percentile(data, 2.5)
    upper = np.percentile(data, 97.5)
    return f"{median:.2f} ({lower:.2f}; {upper:.2f})".replace('.', ',')

def evaluate_feature_with_jouden_j_bootstrap(feature_series, y_data, n_bootstraps=1000, random_seed=42):
    """
    Оценивает качество признака с помощью бутстрэп-оценки доверительных интервалов для ROC AUC,
    чувствительности, специфичности и порога по Jouden's J.
    Строит ROC-кривую с доверительными интервалами.

    Параметры:
    -----------
    feature_series : array-like
        Значения признака.
    y_data : array-like
        Бинарные метки классов (0/1).
    n_bootstraps : int
        Количество бутстрэп-итераций.
    random_seed : int
        Фиксирует генератор случайных чисел для воспроизводимости.

    Возвращает:
    -----------
    dict с медианой и 95% ДИ для roc_auc, sensitivity, specificity, threshold
    """
    y_true = np.array(y_data)
    feature_values = np.array(feature_series)
    rng = np.random.RandomState(random_seed)

    tprs_boot = []
    fprs_boot = []
    aucs = []
    sensitivities = []
    specificities = []
    thresholds_j = []

    base_fpr = np.linspace(0, 1, 100)

    for i in range(n_bootstraps):
        # Генерация бутстрэп-выборки с сохранением баланса классов
        indices = rng.choice(len(y_true), size=len(y_true), replace=True)
        if len(np.unique(y_true[indices])) < 2:
            # Пропускаем выборки без обоих классов
            continue

        y_bs = np.where(y_true[indices]==0, 1, 0)
        y_bs = y_true[indices]
        f_bs = feature_values[indices]
        sorted_indices = np.argsort(f_bs)

        # Сортируем f_bs и y_bs по этим индексам
        #f_bs = f_bs[sorted_indices]
        #y_bs = y_bs[sorted_indices]


        fpr, tpr, thresholds = roc_curve(y_bs, f_bs)
        auc = roc_auc_score(y_bs, f_bs)

        # Jouden's J statistic
        J = tpr - fpr
        ix = np.argmax(J)
        threshold_j = thresholds[ix]
        sensitivity = tpr[ix]
        specificity = 1 - fpr[ix]

        # Интерполяция TPR на базовый FPR для усреднения
        tpr_interp = np.interp(base_fpr, fpr, tpr)
        tpr_interp[0] = 0.0

        tprs_boot.append(tpr_interp)
        fprs_boot.append(base_fpr)
        aucs.append(auc)
        sensitivities.append(sensitivity)
        specificities.append(specificity)
        thresholds_j.append(threshold_j)

    tprs_boot = np.array(tprs_boot)
    aucs = np.array(aucs)
    sensitivities = np.array(sensitivities)
    specificities = np.array(specificities)
    thresholds_j = np.array(thresholds_j)

    mean_tpr = np.median(tprs_boot, axis=0)
    lower_tpr = np.percentile(tprs_boot, 2.5, axis=0)
    upper_tpr = np.percentile(tprs_boot, 97.5, axis=0)

    median_auc = np.median(aucs)
    ci_auc = (np.percentile(aucs, 2.5), np.percentile(aucs, 97.5))

    median_sens = np.median(sensitivities)
    ci_sens = (np.percentile(sensitivities, 2.5), np.percentile(sensitivities, 97.5))

    median_spec = np.median(specificities)
    ci_spec = (np.percentile(specificities, 2.5), np.percentile(specificities, 97.5))

    median_thresh = np.median(thresholds_j)
    ci_thresh = (np.percentile(thresholds_j, 2.5), np.percentile(thresholds_j, 97.5))

    J = mean_tpr - base_fpr
    ix = np.argmax(J)
    # Построение графика ROC с доверительными интервалами
    plt.figure(figsize=(8, 6))
    plt.plot(base_fpr, mean_tpr, color='blue', lw=2, label=f'ROC (AUC median = {median_auc:.2f})')
    plt.fill_between(base_fpr, lower_tpr, upper_tpr, color='blue', alpha=0.2, label='95% CI TPR')
    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Случайный классификатор')
    plt.scatter(base_fpr[ix], mean_tpr[ix], color='red', label=f'Порог = {median_thresh:.2f}')
    plt.xlabel('1 - Специфичность (False Positive Rate)')
    plt.ylabel('Чувствительность (True Positive Rate)')
    plt.title('ROC-кривая с 95% доверительным интервалом')
    plt.legend(loc='lower right')
    plt.grid(True)

    # Вывод статистики под графиком
    print(
        f"AUC: {CI(aucs)}\n"
        f"Чувствительность: {CI(sensitivities)}\n"
        f"Специфичность: {CI(specificities)}\n"
        f"Порог (Jouden's J): {CI(thresholds_j)}"
    )
    #plt.gcf().text(0.15, -0.15, stats_text, fontsize=10, ha='left', va='top', family='monospace')

    plt.show()

    return {
        'roc_auc': (median_auc, ci_auc),
        'sensitivity': (median_sens, ci_sens),
        'specificity': (median_spec, ci_spec),
        'threshold': (median_thresh, ci_thresh)
    }

features = x_data.columns

for i in features:
  print(i)
  data = X[i]
  data = data.dropna()
  metka = X.group
  metka = X.group[data.index]
  ans = evaluate_feature_with_jouden_j_bootstrap(data, metka)

  #print('AUC: ', CI(ans['roc_auc']))
  #print('Чувствительность: ', CI(ans['sensitivity']))
  #print('Специфичность: ', CI(1 - ans['specificity']))

"""# Модели машинного обучения"""

def CI(data):
  return(f"{np.percentile(data, 50):.2f} ({np.percentile(data, 2.5):.2f}; {np.percentile(data, 97.5):.2f})".replace('.', ','))
def evaluate(y_true, y_pred):
    fpr, tpr, thresholds = roc_curve(y_true, y_pred)
    specificity = 1 - fpr
    sensitivity = tpr
    youden_index = sensitivity + specificity - 1
    best_idx = np.argmax(youden_index)
    best_sensitivity = sensitivity[best_idx]
    best_specificity = specificity[best_idx]
    roc = roc_auc_score(y_true, y_pred)
    return np.array([roc, best_sensitivity, best_specificity])

def get_feature_importance(best_model, X_train):

    explainer = shap.LinearExplainer(best_model, X_train, feature_perturbation = 'correlation_dependent')
    # Вычисляем SHAP-значения для всех классов (если задача бинарная, shap_values[1] — для положительного класса)
    shap_values = explainer.shap_values(X_train)
    # Для бинарной классификации shap_values.shape = (2, n_samples, n_features)
    # Для многоклассовой — список массивов для каждого класса
    # Берем для положительного класса (обычно shap_values[1])
    # Средняя абсолютная важность по признакам
    #vals = np.abs(shap_values[1]).mean(1)
    vals = np.abs(shap_values).mean(0)
    return vals

# Инициализация моделей
svc = SVC(probability=True, random_state=42, class_weight = 'balanced')
catboost = CatBoostClassifier(class_weights = [1, 2], random_state=42, verbose=0)

# Параметры для GridSearch
param_grid_svc = {
   # 'C': [0.1, 1, 10],
    'kernel': ['linear'],
   # 'gamma': ['scale'],
    'class_weight' :['balanced']
}

param_grid_catboost = {
   # 'depth': [2, 4, 6],                   # небольшая и средняя глубина деревьев
   # 'learning_rate': [0.01,  0.1],  # маленькие значения для плавного обучения
    'iterations': [200],     # достаточное число итераций
   # 'l2_leaf_reg': [3, 5, 7, 9],         # L2-регуляризация для борьбы с переобучением
    #'bagging_temperature': [0, 1, 2],    # параметр для случайности и уменьшения переобучения
   # 'random_strength': [1, 2, 3]          # дополнительная случайность
}

log = 1 #если 1, то переменные подвергаются процедуре логарифмирования, 0 - без логарифмирования
alpha = 0.95

metrics_model_train = np.array([])
metrics_model_test = np.array([])
best_features = np.array([])
importances = np.array([])


#Для обучения модели SVC с линейным ядром: mode='svc', param_grid = param_grid_svc, kernel = 'linear'
#Для обучения модели SVC с RBF-ядром: mode='svc', param_grid = param_grid_svc, kernel = 'rbf
#Для обучения модели Catboost: mode = 'cat', prarm_grid = param_grid_catboost


mode = 'svc'
if mode=='cat':
    model = catboost
    param_grid = param_grid_catboost
else:
    model = svc
    param_grid = param_grid_svc

n_iterations = 100

"""Обучение модели"""

# @title
for i in tqdm(range(n_iterations)):
    # Бутстрэп с сохранением баланса классов
    X_bs, y_bs = resample(x_data, y_data, stratify=y_data, replace=True, random_state=i)

    split_idx = int(0.8 * len(X_bs))
    X_train, X_test = X_bs[:split_idx], X_bs[split_idx:]
    y_train, y_test = y_bs[:split_idx], y_bs[split_idx:]

    # Преобразование данных
    if log==1:
        X_train = log_transform(X_train, features)
        X_test = log_transform(X_test, features)

    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)

    # --- SVC с GridSearch ---
    grid= GridSearchCV(model, param_grid, scoring='roc_auc', cv=5, n_jobs=-1)
    grid.fit(X_train, y_train)
    best_model = grid.best_estimator_

    best_model.fit(X_train, y_train)

    feature_importance = get_feature_importance(best_model, X_train)

    important_features = np.array([0,1,2,3,4,5,6,7,8,9,10,11])[feature_importance>np.percentile(feature_importance, 50)]
    best_features = np.append(best_features, important_features, axis = 0)

    best_model.fit(X_train[:,important_features], y_train)

    feature_importance = get_feature_importance(best_model, X_train[:,important_features])
    importances = np.append(importances, feature_importance, axis = 0)

    preds_train = best_model.predict_proba(X_train[:,important_features])[:, 1]
    preds_test = best_model.predict_proba(X_test[:,important_features])[:, 1]

    metrics_train = evaluate(y_train, preds_train)
    metrics_test = evaluate(y_test, preds_test)
    metrics_model_train = np.append(metrics_model_train, metrics_train, axis = 0)
    metrics_model_test = np.append(metrics_model_test, metrics_test, axis = 0)

metrics_model_train = metrics_model_train.reshape((100, 3))
metrics_model_test = metrics_model_test.reshape((100, 3))
k = 0

"""Метрики качества модели"""

results = pd.DataFrame(np.array([[str(CI(metrics_model_train[:,i])), str(CI(metrics_model_test[:,i]))] for i in range(3)]), columns = ['train', 'test'], index = ['ROC-AUC', 'Чувствительность', 'Специфичность'])
results.T.style.set_table_styles([
    {'selector': 'th, td', 'props': [('font-size', '16pt')]}
])

"""# Визуализация важности признаков для модели на основе SHAP-значений"""

# Посчитаем частоту вхождения каждого признака
unique_features, counts = np.unique(best_features, return_counts=True)
print(counts.shape)
# Создаём DataFrame для удобства
df = pd.DataFrame({
    'feature': features,
    'count': counts
})
sns.barplot(data = df,y =  'feature', x = 'count', orient = 'h')
plt.show()
# Считаем среднюю важность для каждого признака
mean_importances = []
for feature in unique_features:
    mask = best_features == feature
    mean_importances.append(importances[mask].mean())
df['mean_importance'] = mean_importances

# Сортируем по частоте (count) по убыванию
df = df.sort_values('count', ascending=False)


count_norm = (df['count'] - np.mean(df['count']) / np.std(df['count']))
palette = sns.color_palette("coolwarm", n_colors=len(df))
colors = [palette[i] for i in np.argsort(count_norm)]
print(np.argsort(count_norm))

plt.figure(figsize=(8, 6))
ax = sns.barplot(data=df, x='mean_importance', y='feature',  orient='h')

for i, (value, feature) in enumerate(zip(df['mean_importance'], df['feature'])):
    offset = max(0.01, 0.01 * abs(value))
    x_pos = value + offset -0.007 if value >= 0 else value - offset
    ax.text(x_pos, i, f'{value:.3f}', va='center', ha='left' if value >= 0 else 'right')
ax.margins(x=0.1)

# Найдем индекс, где count пересекает среднее значение
count_sorted = df['count'].sort_values(ascending=False)
mean_count = np.percentile(df['count'], 50)
split_idx = len(count_sorted[count_sorted > mean_count])

# Добавляем горизонтальную пунктирную красную линию между соответствующими признаками
if 0 < split_idx < len(df):
    # В горизонтальном barplot y-координаты идут от 0 до len(df)-1, линия между split_idx-1 и split_idx
    ax.axhline(y=split_idx - 0.5, color='red', linestyle='--', linewidth=2)

plt.title('Средняя важность признаков, отсортированных по частоте вхождения')
plt.tight_layout()
plt.xlabel('Средние коэффициенты модели')
plt.ylabel('Признаки')
plt.show()